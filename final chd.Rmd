---
title: "R Notebook"
output: html_notebook
---

#Team members: Bhagya,Manisha,Nikki


# Project: Prediction of Cardiovascular Stroke

# Problem: Which age groups and genders are more prone to heart stroke?

# Data Description

#Male : 0 = Female; 1 = Male
#age: age at exam time.
#education: 1 = Some High School; 2 = High School or GED; 3 = Some College or Vocational School; 4 =college
#currentSmoker0 = nonsmoker; 1 = smoker
#cigsPerDay: number of cigarettes smoked per day (estimated average)
#BPMeds0 = Not on Blood Pressure medications; 1 = Is on Blood Pressure medications
#prevalentStroke
#prevalentHyp
#diabetes: 0 = No; 1 = Yes
#totChol-mg/dL
#sysBP-mmHg
#diaBP-mmHg
#BMI: Body Mass Index calculated as: Weight (kg) / Height(meter-squared)
#heartRate-Beats/Min (Ventricular)
#glucose-mg/dL
#TenYearCHD


# Install libraries
```{r}
#install.packages("readr)
#install.packages("caret)
#install.packages("corrplot)
#install.packages("class)
#install.packages("rpart)
#install.packages("e1071)
#install.packages("ROCR")
#install.packages("pROC)
#install.packages("tidyverse)
#install.packages(cluster)
#install.packages("factoextra")
#install.packages("ISLR)
#install.packages("caTools")
#install.packages("RMySQL")
#install.packages("gridExtra")
#install.packages("PerformanceAnalytics")
#install.packages("arules")
#install.packages("arulesViz")
```

# Load libraries
```{r}
library(readr)
library(caret)
library(corrplot)
library(class)
library(rpart)
library(rpart.plot)
library(party)
library(e1071)
library(ROCR)
library(pROC)
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms & visualization
library(ISLR)
library(caTools)
library(RMySQL)
library(gridExtra)
library(PerformanceAnalytics)
```

# connect from AWS database
```{r}
con <- dbConnect(MySQL(),
                             user = 'bigdata',
                             password = 'Best2019',
                             dbname = 'bigdata',
                             host = 'bigdata.cuvl8scby0ib.us-east-1.rds.amazonaws.com',
                             port = 3306)
```

# Import the data
```{r}
# send the query 

df <- dbSendQuery(con,"SELECT * FROM cvdata")
#fecth() converts the query results (stored on the server) to a local data frame
diseases<- fetch(df, n = -1)
summary(diseases)
print(diseases)
```




#  Rename the datafile
```{r}
framingham_heart_disease <- diseases
```
#  Remove missing values
```{r}
framingham_heart_disease <- drop_na(framingham_heart_disease)
print(framingham_heart_disease)
```


# Correlation
```{r}
corrr <-cor(framingham_heart_disease[5:16])
corrplot(corrr ,method="number",main = "correlatiom matrix")
```
```{r}
chart.Correlation(corrr, histogram = TRUE, pch = 19)
```

# Changing numbers to male and female
```{r}
framingham_heart_disease$sex[framingham_heart_disease$sex== 1] = "Male"
framingham_heart_disease$sex[framingham_heart_disease$sex== 0] = "Female"
```

# Exploratory Analysis
```{r}
framingham_heart_disease$sex <-as.factor(framingham_heart_disease$sex)
ggplot(framingham_heart_disease,aes(x=age,y=cigsPerDay/30))+
         geom_bar(aes(fill=sex),stat="identity")+
            labs(x="Age",y="Current Smoker",title="Current smokers by age and gender")
```

```{r}
ggplot(data = framingham_heart_disease, mapping = aes(x = as.factor(sex), y = currentSmoker,color = sex) ) + geom_bar(stat = "identity") + 
    labs(x = "Gender Group", y = "Smoker Rate", title = "Smokers by Gender") + theme(legend.position="none")
```

```{r}
ggplot(data = framingham_heart_disease, mapping = aes(x = sex, y = cigsPerDay, color = sex)) + geom_bar(stat = "identity") + 
    labs(x = "Gender Group", y = "Cigarettes Consumption per day ", title = "Cigarettes Consumption per Day  by Gender")  +  theme(legend.position="none")
```

```{r}
ggplot(data = framingham_heart_disease, mapping = aes(x = sex, y = totChol, color = sex)) + 
  coord_flip()+ geom_bar(stat = "identity") + labs(x = "Gender Group", y = "Cholestrol Level by Gender ", 
      title = "Cholestrol level by Gender")+  theme(legend.position="none")
```

```{r}
ggplot(framingham_heart_disease,aes(x=age,y=totChol,color=sex))+geom_point()+facet_wrap(~sex)+
  scale_y_continuous(limits=c(0,600))
```


```{r}
ggplot(framingham_heart_disease,aes(x = age)) + geom_histogram(bins =30,fill ="red") + 
  theme_bw() + theme_classic() +labs(title="age distribution",y="number of people")
ggplot(framingham_heart_disease,aes(x =sex, fill=sex)) + geom_bar(width = 0.2, color='black') + geom_text(stat = 'count',aes(label =..count..)) + theme_bw() + theme_classic() +labs(y="number of count",title="Gender Distribution")
```

```{r}
ggplot(framingham_heart_disease,aes(x=age,y=totChol, color = sex))+geom_point(alpha=0.7)+facet_grid(~sex)+theme(legend.position="none")+
  labs(title = "Gender : Cholestrol Level by Age ", x = "Age Group",
                                            y = "Cholestrol Level") + theme_bw()
```


```{r}
ggplot(framingham_heart_disease,aes(x=education,y=BMI/100,color = as.factor(framingham_heart_disease$education)))+geom_bar(stat="identity")+ 
  labs(title = "Temperatures\n", x = "TY [Â°C]", y = "Txxx", color = "Legend Title\n") +
  scale_color_manual(labels = c("1- High School", "2 - Assocciate Degree","3 - Bachelors Degree","4 -Masters Degree"), values = c("blue",   "red","yellow","pink")) +
  facet_grid(currentSmoker~sex) + labs(title = "Gender : BMI by Education ", x = "Education Level", y = "Body Mass Index (BMI)")
```


```{r}
ggplot(framingham_heart_disease,aes(x=sex,y=heartRate,color=sex))+geom_boxplot()
  
```




#cluster Analysis
#Hierarchical clustering can't handle big data well but K Means clustering can. This is because the time complexity of K Means is linear i.e. O(n) while that of hierarchical clustering is quadratic i.e. O(n2).
#k-means clustering
#given 3 clusters by age group
```{r}
set.seed(20)
data <- diseases
df <- scale(data[,-17])
k2 <- kmeans(df, centers = 3, nstart = 25)
fviz_cluster(k2, data = df)
df %>%
  as_tibble() %>%
  mutate(cluster = k2$cluster,
         ages = row.names(framingham_heart_disease)) %>%
  ggplot(aes(x= age, y= heartRate,color = as.factor(cluster), label = ages)) +
  geom_text()
# checking cluster for 4,5,6 and visualizing
k3 <- kmeans(df, centers = 4, nstart = 25)
k4 <- kmeans(df, centers = 5, nstart = 25)
k5 <- kmeans(df, centers = 6, nstart = 25)

# plots to compare
p1 <- fviz_cluster(k2, geom = "point", data = df) + ggtitle("k = 3")
p2 <- fviz_cluster(k3, geom = "point",  data = df) + ggtitle("k =4")
p3 <- fviz_cluster(k4, geom = "point",  data = df) + ggtitle("k = 5")
p4 <- fviz_cluster(k5, geom = "point",  data = df) + ggtitle("k = 6")


grid.arrange(p1, p2, p3, p4, nrow = 2)
```

#Determining Optimal Clusters
```{r}
set.seed(123)

# function to compute total within-cluster sum of square 
wss <- function(k) {
  kmeans(df, k, nstart = 25 )$tot.withinss
}

# Compute and plot wss for k = 1 to k = 15
k.values <- 1:15

# extract wss for 2-15 clusters
wss_values <- map_dbl(k.values, wss)

plot(k.values, wss_values,
       type="b", pch = 19, frame = FALSE, 
       xlab="Number of clusters K",
       ylab="Total within-clusters sum of squares")
set.seed(123)

fviz_nbclust(df, kmeans, method = "wss")
```


```{r}
# function to compute average silhouette for k clusters
avg_sil <- function(k) {
  km.res <- kmeans(df, centers = k, nstart = 25)
  ss <- silhouette(km.res$cluster, dist(df))
  mean(ss[, 3])
}

# Compute and plot wss for k = 2 to k = 15
k.values <- 2:15

# extract avg silhouette for 2-15 clusters
avg_sil_values <- map_dbl(k.values, avg_sil)

plot(k.values, avg_sil_values,
       type = "b", pch = 19, frame = FALSE, 
       xlab = "Number of clusters K",
       ylab = "Average Silhouettes")
fviz_nbclust(df, kmeans, method = "silhouette")

```


#Backward elimination linear model
```{r}
bk_lm <- lm(heartRate ~ .,
            data = framingham_heart_disease)
step(bk_lm,direction="backward")
```


# Forward Selection
```{r}
fw_lm <- lm(heartRate ~ .,
            data = framingham_heart_disease)
nullmodel <- lm(heartRate~1, framingham_heart_disease)
step(nullmodel,direction="forward",
     scope = heartRate ~ sex + age + education + currentSmoker + cigsPerDay + 
    BPMeds + prevalentStroke + prevalentHyp + diabetes + totChol + 
    sysBP + diaBP + BMI + glucose + TenYearCHD + Diseases)
```
#Split the data

```{r}
set.seed(123)   #  set seed to ensure you always have same random numbers generated
sample = sample.split(framingham_heart_disease$TenYearCHD,SplitRatio = 0.75) # splits the data in the ratio mentioned in SplitRatio. After splitting marks these rows as logical TRUE and the the remaining are marked as logical FALSE
train1 =subset(framingham_heart_disease,sample ==TRUE) # creates a training dataset named train1 with rows which are marked as TRUE
test1=subset(framingham_heart_disease, sample==FALSE)
```


# Linear regression
```{r}
fit_lm <- lm(heartRate ~ sysBP + sex + cigsPerDay + glucose + diaBP + age + 
               totChol + education + BPMeds + prevalentHyp, data=train1)
summary(fit_lm)
equation1=function(x){
  coef(fit_lm)[2]*x+coef(fit_lm)[1]
  }
equation2=function(x){
  coef(fit_lm)[2]*x+coef(fit_lm)[1]+coef(fit_lm)[3]
  }

ggplot(framingham_heart_disease,aes(y=heartRate,x=totChol,color= sex))+geom_point()+
        stat_function(fun=equation1,geom="line",color=scales::hue_pal()(2)[1])+
        stat_function(fun=equation2,geom="line",color=scales::hue_pal()(2)[2])+labs(x="total cholesterol",y="Heart rate",title = "Heart rate for males and females")
#predict on test data
pred_lm <- predict(fit_lm,test1)
results_lm <- data.frame(Actual =test1$heartRate,Prediction =pred_lm)
ggplot(data= results_lm,aes(x= Actual,y=Prediction))+geom_point()+geom_abline()
#predict on new data
newdata <- data.frame(totChol = 650,sysBP= 300, cigsPerDay= 70,glucose = 400,diaBP= 150,
                      sex = "Female",age =50,education =4,BPMeds = 1,prevalentHyp= 1)
 newdata1 <- data.frame(totChol= 650, sysBP= 300,cigsPerDay=70,glucose= 400, diaBP= 150,
                        sex ="Male",age= 50,education=4,BPMeds = 1,prevalentHyp=1)
result <- predict(fit_lm,newdata )
result1 <- predict(fit_lm,newdata1)
cat("The Predicted heartrate for female is" , result,"\n")
cat("The Predicted heartrate for male is" , result1)
```
# Classification Analysis

# Knn algorithm
```{r}
set.seed(123)
#create a random number equal 90% of total number of rows
ran <- sample(1:nrow(framingham_heart_disease),0.75 * nrow(framingham_heart_disease))
 
##the normalization function is created
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
 
##normalization function is created
df_nor <- as.data.frame(lapply(framingham_heart_disease[,c(10,11,12,13,14,15)], nor))
##training dataset extracted
df_train <- df_nor[ran,]

##test dataset extracted
df_test <- df_nor[-ran,]
##the 2nd column of training dataset because that is what we need to predict about testing dataset
##also convert ordered factor to normal factor
df_target <- as.factor(framingham_heart_disease[ran,16])
 
##the actual values of 2nd couln of testing dataset to compaire it with values that will be predicted
##also convert ordered factor to normal factor
test_target <- as.factor(framingham_heart_disease[-ran,16])
##run knn function
 
pred_knn <- knn(df_train,df_test,cl=df_target,k=20)
 
##create the confucion matrix
mat_knn <- table(test_target,pred_knn,dnn=c("Actual","Prediction"))
mat_knn
results_knn <- data.frame(Actual =test_target,Prediction =pred_knn)
#predict on new data
tptn <- nrow(subset(results_knn,Actual == Prediction))
total_size <- length(test_target)
#accuracy
knn_accuracy <- tptn/total_size
cat("The accuracy of Knn model is:",knn_accuracy,"\n")
#precision
tp <- nrow(subset(results_knn,Actual == 1,Prediction == 1))
fp <- nrow(subset(results_knn,Actual == 0,Prediction == 1))
fn <- nrow(subset(results_knn,Actual == 1,Prediction == 0))
knn_precision <- tp/(tp+fp)
cat("The Precision of Knn model is:",knn_precision,"\n")
#recall
knn_recall <- tp/(tp+fn)
cat("The recall of Knn model is:",knn_recall,"\n")
knn <- ifelse(results_knn$Actual == results_knn$Prediction,1,0)
knn <- as.data.frame(knn)
knn$models <- paste("Knn_model")
colnames(knn)[1]<- "Accuracy"
```
# Features By Importance
```{r}
framingham_heart_disease$TenYearCHD <- as.factor(framingham_heart_disease$TenYearCHD)
# prepare training scheme
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- train(data=framingham_heart_disease,TenYearCHD ~ ., method="lvq", preProcess="scale",
               trControl=control)
# estimate variable importance
library(mlbench)
#importance <- varImp(model)
# summarize importance
#print(importance)
# plot importance
#plot(importance)
```


# Logistic regression
```{r}
fit_glm <- glm(TenYearCHD~ age+sysBP+prevalentHyp+diaBP+totChol+BMI+glucose, data = train1, family="binomial"(link="logit"))
pred_glm <- predict(fit_glm,test1, type = "response")
prediction_glm <- ifelse(pred_glm > 0.5,1,0)
mat_glm <-table(test1$TenYearCHD,prediction_glm,dnn=c("Actual","Prediction"))
results_glm <- data.frame(Actual1 =test1$TenYearCHD,Prediction1 =prediction_glm)
tptn1 <- nrow(subset(results_glm,Actual1 == Prediction1))
total_size1 <- nrow(test1)
#accuracy
glm_accuracy <- tptn1/total_size1
cat("The accuracy of logistic model is:",glm_accuracy,"\n")
#precision
tp1 <- nrow(subset(results_glm,Actual1== 1,Prediction1==1))
fp1 <- nrow(subset(results_glm,Actual1 == 0,Prediction1 == 1))
fn1 <- nrow(subset(results_glm,Actual1 == 1,Prediction1 == 0))
glm_precision <- tp1/(tp1+fp1)
cat("The Precision of logistic model is:",glm_precision,"\n")
#recall
glm_recall <- tp1/(tp1+fn1)
cat("The recall of logistic model is:",glm_recall,"\n")
glm <- ifelse(results_glm$Actual1 == results_glm$Prediction1,1,0)
glm <- as.data.frame(glm)
glm$models <- paste("Glm_model")
colnames(glm)[1]<- "Accuracy"
rocCurve_logit <- roc(response = test1$TenYearCHD,
               predictor = prediction_glm)
auc_curve <- auc(rocCurve_logit)

plot(rocCurve_logit,legacy.axes = TRUE,print.auc = TRUE,col="red",main="ROC(Logistic Regression)")
library(ModelGood)
plot(Roc(list(fit_glm),data=test1))
```

# decision tree

```{r}
prop.table(table(train1$TenYearCHD))
prop.table(table(test1$TenYearCHD))
```
#in both cases the risk of heart stroke is 14%

#changing the TenyearCHD from 0 to no and 1 to yes
```{r}
framingham_heart_disease$tenyrCHD <- ifelse(framingham_heart_disease$TenYearCHD == 1, "yes","no")
framingham_heart_disease <- framingham_heart_disease[,-16]
framingham_heart_disease$tenyrCHD <- as.factor(framingham_heart_disease$tenyrCHD)
```

```{r}
framingham_heart <- framingham_heart_disease
```

```{r}
set.seed(123)
#split the data
sample1 <- sample.split(framingham_heart$tenyrCHD,SplitRatio = 0.75)
train <- subset(framingham_heart,sample1== TRUE)
test <- subset(framingham_heart,sample1== FALSE)
```

#decision tree
```{r}
fit_dc <- ctree(tenyrCHD~ age+sex+education+currentSmoker+cigsPerDay+BPMeds+prevalentStroke+
                  diabetes+sysBP+prevalentHyp+diaBP+totChol+BMI+
                  heartRate+glucose, data = train)
plot(fit_dc)
pred_dc <-predict(fit_dc, test,type= "response")
#confusion matrix
mat_dc <- table(test$tenyrCHD, pred_dc,dnn=c("Actual","Prediction"))
results_ct <- data.frame(Actual2 = test$tenyrCHD,Prediction2 = pred_dc)
tptn2 <- nrow(subset(results_ct,Actual2== Prediction2))
total_size2 <- nrow(test)
#accuracy
ct_accuracy <- tptn2/total_size2
cat("The accuracy of CTree model is:",ct_accuracy,"\n")
#precision
tp2 <- nrow(subset(results_ct,Actual2=="yes",Prediction2=="yes"))
fp2 <- nrow(subset(results_ct,Actual2 == "no",Prediction2 == "yes"))
fn2 <- nrow(subset(results_ct,Actual2 == "yes",Prediction2 == "no"))
ct_precision <- tp2/(tp2+fp2)
cat("The Precision of CTree model is:",ct_precision,"\n")
#recall
ct_recall <- tp2/(tp2+fn2)
cat("The recall of CTree model is:",ct_recall,"\n")
ct <- ifelse(results_ct$Actual2 == results_ct$Prediction2,1,0)
ct <-as.data.frame(ct)
ct$models <- paste("ctree_model")
colnames(ct)[1] <- "Accuracy"

```

# Naive bayes

```{r}
nb_model<- naiveBayes(tenyrCHD~.,data =train,laplace = 1)
pred_nb <- predict(nb_model,test)
mat_nb <- table(test$tenyrCHD,pred_nb,dnn=c("Actual","Prediction"))
results_nb <- data.frame(Actual3 = test$tenyrCHD,Prediction3 = pred_nb)
tptn3 <- nrow(subset(results_nb,Actual3== Prediction3))
total_size3 <- nrow(test)
#accuracy
nb_accuracy <- tptn3/total_size3
cat("The accuracy of Naivebayes model is:",nb_accuracy,"\n")
#precision
tp3 <- nrow(subset(results_nb,Actual3=="yes",Prediction3=="yes"))
fp3 <- nrow(subset(results_nb,Actual3 == "no",Prediction3 == "yes"))
fn3 <- nrow(subset(results_nb,Actual3 == "yes",Prediction3 == "no"))
nb_precision <- tp3/(tp3+fp3)
cat("The Precision of Naivebayes model is:",nb_precision,"\n")
#recall
nb_recall <- tp3/(tp3+fn3)
cat("The recall of Naivebayes model is:",nb_recall,"\n")
nb <- ifelse(results_nb$Actual3 == results_nb$Prediction3,1,0)
nb<- as.data.frame(nb)
nb$models <- paste("Nb_model")
colnames(nb)[1]<-"Accuracy"
```

# Hypothesis testing
```{r}
accuracies <- rbind(knn,glm,nb,ct)
annova <- aov(Accuracy~models,data=accuracies)
summary(annova)
```

# Plot (Accuracies for each model)
```{r}
accu <- data.frame(c(models= "K-nearest neighbor","Logistic","Naivebayes","Decision tree"),
                   c(knn_accuracy,glm_accuracy,nb_accuracy,ct_accuracy))
colnames(accu)[1]<-"models"
colnames(accu)[2]<-"Accuracy"
ggplot(data=accu,mapping=aes(x=models,y=Accuracy, fill = models))+geom_bar(stat="identity")+
  labs(x="Models",y="Accuracies",title = "Accuracy vs Models")
  
```

#  Results
```{r}
#knn results percentage
knn_data <-as.data.frame(pred_knn)
test$predicted_knn <- knn_data$pred_knn
ksub1<- subset(test,age>=30 & age<=45 )
ksub1$agegroup <-paste("30-45")
ksub2<- subset(test,age>45 & age<=60 )
ksub2$agegroup <-paste("45-60")
ksub3<- subset(test,age>60 & age<=75 )
ksub3$agegroup <-paste("60-75")
knn_pt <- rbind(ksub1,ksub2,ksub3)
kpt_pred1 <- subset(knn_pt,predicted_knn==1)
ggplot(kpt_pred1,aes(x=agegroup,fill=sex))+geom_bar(position = "dodge")
```


```{r}
#logistic percentage results
glm_data <-as.data.frame(prediction_glm)
test$predicted_glm <- glm_data$prediction_glm
gsub1<- subset(test,age>=30 & age<=45 )
gsub1$agegroup <-paste("30-45")
gsub2<- subset(test,age>45 & age<=60 )
gsub2$agegroup <-paste("45-60")
gsub3<- subset(test,age>60 & age<=75 )
gsub3$agegroup <-paste("60-75")
glm_pt <- rbind(gsub1,gsub2,gsub3)
gpt_pred1 <- subset(glm_pt,predicted_glm==1)
ggplot(gpt_pred1,aes(x=agegroup,fill=sex))+geom_bar(position = "dodge")
```


```{r}
#decision tree percentage results
dc_data <-as.data.frame(pred_dc)
test$predicted_dc <- dc_data$pred_dc
sub1<- subset(test,age>=30 & age<=45 )
sub1$agegroup <-paste("30-45")
sub2<- subset(test,age>45 & age<=60 )
sub2$agegroup <-paste("45-60")
sub3<- subset(test,age>60 & age<=75 )
sub3$agegroup <-paste("60-75")
dc_pt <- rbind(sub1,sub2,sub3)
dpt_pred1 <- subset(dc_pt,predicted_dc=="yes")
ggplot(dpt_pred1,aes(x=agegroup,fill=sex))+geom_bar(position = "dodge")
```

```{r}
#naivebayes results percentage 
nB_data <-as.data.frame(pred_nb)
test$predicted_nb <- nB_data$pred_nb
nBsub1<- subset(test,age>=30 & age<=45 )
nBsub1$agegroup <-paste("30-45")
nBsub2<- subset(test,age>45 & age<=60 )
nBsub2$agegroup <-paste("45-60")
nBsub3<- subset(test,age>60 & age<=75 )
nBsub3$agegroup <-paste("60-75")
nB_pt <- rbind(nBsub1,nBsub2,nBsub3)
nBpt_pred1 <- subset(nB_pt,predicted_nb=="yes")
#outcomenB<- nrow(nBpt_act1)/nrow(nB_pt)
ggplot(nBpt_pred1,aes(x=agegroup,fill=sex))+geom_bar(position = "dodge")
```


# Performance
```{r}
results_ct$Prediction2 <- ifelse(results_ct$Prediction2 == "yes",1,0)
# List of predictions
preds_list <- list(results_knn$Prediction,results_glm$Prediction1, results_ct$Prediction2, results_nb$Prediction3)

# List of actual values (same for all)
m <- length(preds_list)
actuals_list <- rep(list(test$tenyrCHD), m)

# Plot the ROC curves
pred <- prediction(preds_list, actuals_list)
rocs <- performance(pred, "tpr", "fpr")
plot(rocs, col = as.list(1:m), main = "Test Set ROC Curves")
legend(x = "bottomright", 
       legend = c("K-Nearest Neighbor","Logistic Regression","Decision Tree", "Naive Bayes"),fill=c("yellow","blue","green","red"))
#ROC curves are commonly used to characterize the sensitivity/specificity tradeoffs for a binary classifier. ... The ROC curve plots true positive rate against false positive rate.
```

# Text Analysis
```{r}
library(arules)
library(arulesViz)
texthealth <- framingham_heart_disease
texthealth$education[texthealth$education== 1] = "Some High School"
texthealth$education[texthealth$education== 2] = "High School or GED"
texthealth$education[texthealth$education== 3] = 
  "Some College or Vocational School"
texthealth$education[texthealth$education== 4] = "college"
texthealth$currentSmoker[texthealth$currentSmoker== 0] = "nonsmoker"
texthealth$currentSmoker[texthealth$currentSmoker== 1] = "smoker"
texthealth$BPMeds[texthealth$BPMeds== 0] = "No BP Medictaion"
texthealth$BPMeds[texthealth$BPMeds== 1] = "BP Medictaion"
texthealth$prevalentStroke[texthealth$prevalentStroke== 0] = "No previous stroke"
texthealth$prevalentStroke[texthealth$prevalentStroke== 1] = "previous stroke"
texthealth$prevalentHyp[texthealth$prevalentHyp== 0] = "No Hyp"
texthealth$prevalentHyp[texthealth$prevalentHyp== 1] = "Hyp"
texthealth$diabetes[texthealth$diabetes== 0] = "No diabetes"
texthealth$diabetes[texthealth$diabetes== 1] = "diabetes"
library(tm)
texthealth <- subset(texthealth,tenyrCHD=="yes")
dis.corpus <- Corpus(VectorSource(texthealth$Diseases))
dis.corpus <- tm_map(dis.corpus, removePunctuation)

dis.corpus <- tm_map(dis.corpus, tolower)
dis.corpus <- tm_map(dis.corpus, function(x) removeWords(x, stopwords("english")))
tdm <- TermDocumentMatrix(dis.corpus)
library(quanteda)
#install.packages("tm")
inspect(tdm)
library(wordcloud)
library(RColorBrewer)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
disdata <- data.frame(word = names(v),freq=v)
pal <- brewer.pal(5, "BuGn")
pal <- pal[-(1:2)]
png("wordcloud.png", width=200,height=100)
```
# plot text analysis
```{r}
wordcloud(disdata$word,disdata$freq, scale=c(3,.3),min.freq=2,max.words=50, random.order=T,
          rot.per=.15, colors=pal, vfont=c("sans serif","plain"))

```


#another approch of text analysis
```{r}

dfCorpus <- SimpleCorpus(VectorSource(texthealth$Diseases))
#View(corpus)
# 1. Stripping any extra white space:
dfCorpus <- tm_map(dfCorpus, stripWhitespace)
# 2. Transforming everything to lowercase
dfCorpus <- tm_map(dfCorpus, content_transformer(tolower))
# 3. Removing numbers 
dfCorpus <- tm_map(dfCorpus, removeNumbers)
# 4. Removing punctuation
dfCorpus <- tm_map(dfCorpus, removePunctuation)
# 5. Removing stop words
dfCorpus <- tm_map(dfCorpus, removeWords, stopwords("english"))
dfCorpus[[1]]$content
dfCorpus <- tm_map(dfCorpus, stemDocument)
dfCorpus[[1]]$content
DTM <- DocumentTermMatrix(dfCorpus)
#View(DTM)
inspect(DTM)
sums <- as.data.frame(colSums(as.matrix(DTM)))
library(tibble)
library(dplyr)
sums <- rownames_to_column(sums) 
colnames(sums) <- c("term", "count")
sums <- arrange(sums, desc(count))
head <- sums[1:5,]
wordcloud(words = head$term, freq = head$count, min.freq = 1000,
  max.words=1000, random.order=FALSE, rot.per=0.35, 
  colors=brewer.pal(8, "Dark2"))
```



#another approach of naive bayes
```{r}
heart_disease <- framingham_heart_disease[,-16]

heart_disease$heartstroke <- ifelse(heart_disease$sysBP > 130 & heart_disease$diaBP > 80,
                                    "Stage1Hypertension","no stroke")
heart_disease$heartstroke <- as.factor(heart_disease$heartstroke)
sample1 <- sample.split(heart_disease$heartstroke,SplitRatio = 0.75)
trainingset <- subset(heart_disease,sample1 == TRUE)
testset <- subset(heart_disease,sample1 == FALSE)

fit_nb <- naiveBayes(heartstroke ~ ., data = trainingset)
fit_nb
pred_nb <- predict(fit_nb, testset, type = "class") 
mat_nb <- table(testset$heartstroke,pred_nb)
confusionMatrix(mat_nb)
```


